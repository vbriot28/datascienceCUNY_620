{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment # 10 - Documents Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the required packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import random\n",
    "import nltk\n",
    "from nltk import word_tokenize, WordNetLemmatizer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics, svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Load data\n",
    "\n",
    "This data set was downloaded to a local drive in the .\\data directory and will be loaded from there.  Original data set can be found at: https://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection  \n",
    "\n",
    "This data set consist of a collection of text message that have been identified as 'spam' or 'ham' (non-spam). The format of the data is one message per line with 2 columns, the first column is the identifier (ham/spam), the other column is the message. The columns are separated by space and there is no column header.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Thanks love. But am i doing torch or bold.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nope. I just forgot. Will show next week</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>I'm back &amp;amp; we're packing the car now, I'll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>I not at home now lei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>So when do you wanna gym?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0                                                  1\n",
       "0  ham         Thanks love. But am i doing torch or bold.\n",
       "1  ham           Nope. I just forgot. Will show next week\n",
       "2  ham  I'm back &amp; we're packing the car now, I'll...\n",
       "3  ham                           I not at home now lei...\n",
       "4  ham                          So when do you wanna gym?"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use Pandas to load data\n",
    "df = pd.read_table('data/SMSSpamCollection.txt', header=None)\n",
    "\n",
    "# Shuffle the rows\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5572 entries, 0 to 5571\n",
      "Data columns (total 2 columns):\n",
      "0    5572 non-null object\n",
      "1    5572 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 87.1+ KB\n"
     ]
    }
   ],
   "source": [
    "# Information about messages\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us examine the distribution of spam vs. non-spam messages.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ham</th>\n",
       "      <td>4825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spam</th>\n",
       "      <td>747</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         1\n",
       "0         \n",
       "ham   4825\n",
       "spam   747"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(df[0]).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 6 times as many non-spam as spam. We will need to take this into consideration when creating training set. We will make sure to randomize the data set prior to dividing it.  We might also consider enforcing the same proportion the data when we build our training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Pre-processing the messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prior to building our features, we will look at our messages and determine whether to pre-process them. This is not to have too many features and overfit the model.  We will start by examining the spam messages and non-spam messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>spam</td>\n",
       "      <td>1st wk FREE! Gr8 tones str8 2 u each wk. Txt N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>spam</td>\n",
       "      <td>Fancy a shag? I do.Interested? sextextuk.com t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>spam</td>\n",
       "      <td>URGENT! You have won a 1 week FREE membership ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>spam</td>\n",
       "      <td>XMAS iscoming &amp; ur awarded either £500 CD gift...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>spam</td>\n",
       "      <td>FreeMsg Today's the day if you are ready! I'm ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0                                                  1\n",
       "5   spam  1st wk FREE! Gr8 tones str8 2 u each wk. Txt N...\n",
       "9   spam  Fancy a shag? I do.Interested? sextextuk.com t...\n",
       "12  spam  URGENT! You have won a 1 week FREE membership ...\n",
       "22  spam  XMAS iscoming & ur awarded either £500 CD gift...\n",
       "27  spam  FreeMsg Today's the day if you are ready! I'm ..."
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df[0] == 'spam'][0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From observing the spam messages, we can deduct that spam messages make reference to phone numbers, monetary amounts either in Dollars or in British Pounds ($ and £ repectively), numbers, and in some instance url's.  \n",
    "\n",
    "Since these would like to keep track of them since they seemed indicative of spam we will convert them to words. This will be done with regex.  \n",
    "\n",
    "* url's will be set to urladdr\n",
    "* monatory symbols will be set to monetarysymb  \n",
    "* phone numbers will be set to phonenumr\n",
    "* numbers will be set to numr\n",
    "\n",
    "\n",
    "we will select a few messages that contains these expression so that we can test our processing logic to confirm that we achieve the desired results.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "msg1 = 'XXXMobileMovieClub: To use your credit, click the WAP link in the next txt message or click here>> http://wap. xxxmobilemovieclub.com?n=QJKGIGHJJGCBL'\n",
    "msg2 = 'Thanks for your subscription to Ringtone UK your mobile will be charged £5/month Please confirm by replying YES or NO. If you reply NO you will not be charged'\n",
    "msg3 = '07732584351 - Rodger Burns - MSG = We tried to call you re your reply to our sms for a free nokia mobile + free camcorder. Please call now 08000930705 for delivery tomorrow'\n",
    "msg4 = 'Congrats! 1 year special cinema pass for 2 is yours. call 09061209465 now! C Suprman V, Matrix3, StarWars3, etc all 4 FREE! bx420-ip4-5we. 150pm. Dont miss out! '\n",
    "msg5 = 'As a valued customer, I am pleased to advise you that following recent review of your Mob No. you are awarded with a £1500 Bonus Prize, call 09066364589'\n",
    "msg6 = 'Please call our customer service representative on FREEPHONE 0808 145 4742 between 9am-11pm as you have WON a guaranteed £1000 cash or £5000 prize!'\n",
    "msg7 = 'Are you unique enough? Find out from 30th August. www.areyouunique.co.uk'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tag http[s] as urladdr\n",
    "msg = re.sub(r'(http[s]?\\S+)|(\\www\\.[A-Za-z]{2,4}\\S*)', 'urladdr', msg1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tag $, £ as monetary\n",
    "msg = re.sub(r'\\xc2\\xa3|\\$', 'monatorysymb', msg6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tag phone number\n",
    "msg = re.sub(r'\\b(\\+\\d{1,2}\\s)?\\d?[\\-(.]?\\d{3}\\)?[\\s.-]?\\d{3}[\\s.-]?\\d{4}\\b',\n",
    "    'phonenumbr', msg3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tag number\n",
    "msg = re.sub(r'\\d+(\\.\\d+)?', 'numbr', msg6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "In addition, we will remove the punctuation, relace any whitespace to single space and remove leading and trailing white space, and convert to lower case.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove punctuation\n",
    "msg = re.sub(r'[^\\w\\d\\s]', ' ', msg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove whitespace wtih single space\n",
    "msg = re.sub(r'\\s+', ' ', msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Trimming leading and trailing white space\n",
    "msg = re.sub(r'^\\s+|\\s+?$', '', msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert to lower case\n",
    "msg = msg.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will build a function to do all these transformation and apply them to the total corpus.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function for message processing \n",
    "\n",
    "def process_msg(msg):\n",
    "    \"\"\" Function to modified message with successive regex expression to transform for processing.\"\"\"\n",
    "    #tag http[s] as urladdr\n",
    "    processed_msg = re.sub(r'(http[s]?\\S+)|(\\www\\.[A-Za-z]{2,4}\\S*)', 'urladdr', msg)\n",
    "    # tag $, £ as monetary\n",
    "    processed_msg = re.sub(r'\\xc2\\xa3|\\$', 'monatorysymb', processed_msg)\n",
    "    # tag phone number\n",
    "    processed_msg = re.sub(r'\\b(\\+\\d{1,2}\\s)?\\d?[\\-(.]?\\d{3}\\)?[\\s.-]?\\d{3}[\\s.-]?\\d{4}\\b',\n",
    "    'phonenumbr', processed_msg)\n",
    "    # tag number\n",
    "    processed_msg = re.sub(r'\\d+(\\.\\d+)?', 'numbr', processed_msg)\n",
    "    # Remove punctuation\n",
    "    processed_msg = re.sub(r'[^\\w\\d\\s]', ' ', processed_msg)\n",
    "    # Remove whitespace wtih single space\n",
    "    processed_msg = re.sub(r'\\s+', ' ', processed_msg)\n",
    "    # Trimming leading and trailing white space\n",
    "    processed_msg = re.sub(r'^\\s+|\\s+?$', '', processed_msg)\n",
    "    # Convert to lower case\n",
    "    processed_msg = processed_msg.lower()\n",
    "    \n",
    "    return(processed_msg)\n",
    "\n",
    "df[1] = df[1].apply(process_msg)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Tokenization & Lemmatization\n",
    "\n",
    "We will now remove the StopWord and reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stoplist = stopwords.words('english')\n",
    "\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def process_words(msg):\n",
    "    tokens = word_tokenize(msg)\n",
    "    tokens_tp = []\n",
    "    for word in tokens:\n",
    "        if word not in stoplist:\n",
    "            tokens_tp.append( word )\n",
    "    processed_tokens = [wordnet_lemmatizer.lemmatize(word) for word in tokens_tp]\n",
    "    s_processed_tokesns = ' '.join(processed_tokens)\n",
    "    return (s_processed_tokesns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df[2]=df[1].apply(process_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>thanks love but am i doing torch or bold</td>\n",
       "      <td>thanks love torch bold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>nope i just forgot will show next week</td>\n",
       "      <td>nope forgot show next week</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>i m back amp we re packing the car now i ll le...</td>\n",
       "      <td>back amp packing car let know room</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>i not at home now lei</td>\n",
       "      <td>home lei</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>so when do you wanna gym</td>\n",
       "      <td>wan na gym</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0                                                  1  \\\n",
       "0  ham           thanks love but am i doing torch or bold   \n",
       "1  ham             nope i just forgot will show next week   \n",
       "2  ham  i m back amp we re packing the car now i ll le...   \n",
       "3  ham                              i not at home now lei   \n",
       "4  ham                           so when do you wanna gym   \n",
       "\n",
       "                                    2  \n",
       "0              thanks love torch bold  \n",
       "1          nope forgot show next week  \n",
       "2  back amp packing car let know room  \n",
       "3                            home lei  \n",
       "4                          wan na gym  "
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Vectorization and building features\n",
    "\n",
    "We will first separate the messages and the labels and then use CountVectorizer from sklearn package to build features matrix.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify processed messages and labels\n",
    "messages = df[1]\n",
    "labels = df[0]\n",
    "# Encode labels with 0,1\n",
    "# Encode the class labels as numbers\n",
    "le = LabelEncoder()\n",
    "labels_enc = le.fit_transform(labels)\n",
    "\n",
    "# Use TfidVectorizer to build matrix, we will only consider 1gram\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 1))\n",
    "X = vectorizer.fit_transform(messages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 7986)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Training and Evaluating Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Prepare the training and test sets using an 80/20 split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    labels_enc,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=labels_enc\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the Naive Bayes model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_nb = MultinomialNB()\n",
    "clf_nb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the support vector machines (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='hinge', max_iter=1000, multi_class='ovr',\n",
       "     penalty='l2', random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train SVM with a linear kernel on the training set\n",
    "clf_svm = svm.LinearSVC(loss='hinge')\n",
    "clf_svm.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now predict using both model on our text data set and we will compare the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Evaluate the classifier on the test set\n",
    "y_pred_nb = clf_nb.predict(X_test)\n",
    "y_pred_svm = clf_svm.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now compute the F1 score for both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute the F1 scores\n",
    "f1_nb = metrics.f1_score(y_test, y_pred_nb)\n",
    "f1_svm = metrics.f1_score(y_test, y_pred_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score for Naive Bayes : 0.866920152091\n",
      "F1 score for SVM         : 0.932384341637\n"
     ]
    }
   ],
   "source": [
    "print('F1 score for Naive Bayes : ' + str(f1_nb))\n",
    "print('F1 score for SVM         : ' + str(f1_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It will appear that the SVM model is performing much better. We will now look at the confusion matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Display a confusion matrices\n",
    "conf_nb = pd.DataFrame(\n",
    "    metrics.confusion_matrix(y_test, y_pred_nb),\n",
    "    index=[['actual', 'actual'], ['spam', 'ham']],\n",
    "    columns=[['predicted', 'predicted'], ['spam', 'ham']]\n",
    ")\n",
    "conf_svm = pd.DataFrame(\n",
    "    metrics.confusion_matrix(y_test, y_pred_svm),\n",
    "    index=[['actual', 'actual'], ['spam', 'ham']],\n",
    "    columns=[['predicted', 'predicted'], ['spam', 'ham']]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for Naive Bayes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">predicted</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>spam</th>\n",
       "      <th>ham</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">actual</th>\n",
       "      <th>spam</th>\n",
       "      <td>966</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ham</th>\n",
       "      <td>35</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            predicted     \n",
       "                 spam  ham\n",
       "actual spam       966    0\n",
       "       ham         35  114"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print ('Confusion Matrix for Naive Bayes')\n",
    "conf_nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for SVM\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">predicted</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>spam</th>\n",
       "      <th>ham</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">actual</th>\n",
       "      <th>spam</th>\n",
       "      <td>965</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ham</th>\n",
       "      <td>18</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            predicted     \n",
       "                 spam  ham\n",
       "actual spam       965    1\n",
       "       ham         18  131"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print ('Confusion Matrix for SVM')\n",
    "conf_svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Athough both model are very good at predicting spam and fairly good at predicting ham, SVM has a lower level of false positive than Naive Bayes (18 to 35)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. References\n",
    "\n",
    "* Natural Language Processing with Python\n",
    "* http://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html\n",
    "* http://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html\n",
    "* http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
    "* http://scikit-learn.org/stable/modules/feature_extraction.html\n",
    "* https://cambridgespark.com/content/tutorials/implementing-your-own-spam-filter/index.html\n",
    "* https://github.com/redwanhuq/machine_learning/blob/master/sms_spam_filter.ipynb\n",
    "* https://radimrehurek.com/data_science_python/\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
